{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.stats\n",
    "import math\n",
    "import statsmodels.stats.multitest as multest\n",
    "import statsmodels.sandbox.stats.multicomp as mulcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute TCP (Therapeutically Correlated Pair) scores with a formula of \"Z observation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### A375\n",
      "##### HT29\n"
     ]
    }
   ],
   "source": [
    "def get_z(r):\n",
    "    if r==1:\n",
    "        r=0.9999\n",
    "    if r==-1:\n",
    "        r=-0.9999\n",
    "    return (math.log(1+r)-math.log(1-r))*0.5\n",
    "\n",
    "def get_corr_unstack(df1,col_name):\n",
    "    cor_df=df1.corr('pearson')\n",
    "    cor_df=cor_df.unstack().to_frame()\n",
    "    cor_df.columns=[col_name]\n",
    "    cor_df.index.names=[None, None]\n",
    "    return cor_df\n",
    "    \n",
    "file_names=glob.glob('result/TF_activity_viper/*_v.txt')  \n",
    "\n",
    "corr_merged_df = pd.DataFrame()\n",
    "for file_name in file_names:\n",
    "    cell=file_name.split(\"_\")[-2]\n",
    "    print('#####',cell)\n",
    "    \n",
    "    anal_data=pd.read_table(file_name, sep='\\t',engine='python')\n",
    "    \n",
    "    dataE=anal_data.loc[anal_data['effect']==1, [col for col in anal_data.columns if col!='effect']]\n",
    "    dataIE=anal_data.loc[anal_data['effect']==0, [col for col in anal_data.columns if col!='effect']]\n",
    "    \n",
    "    corrE=get_corr_unstack(dataE, 'corrE')\n",
    "    corrIE=get_corr_unstack(dataIE, 'corrIE')\n",
    "\n",
    "    corr_df=pd.concat([corrE,corrIE], axis=1)\n",
    "   \n",
    "    corr_df['corrEZ']=corr_df['corrE'].map(get_z)\n",
    "    corr_df['corrIEZ']=corr_df['corrIE'].map(get_z)\n",
    "    \n",
    "    denorm_of_zobs=np.sqrt(1/(len(dataE)-3)+1/(len(dataIE)-3))\n",
    "    corr_df['Zobs(TCPS)']=corr_df.apply(lambda row: (row['corrEZ']-row['corrIEZ'])/denorm_of_zobs, axis=1)\n",
    "    corr_df['p_value']=corr_df['Zobs(TCPS)'].map(lambda x: scipy.stats.norm.sf(abs(x))*2)\n",
    "\n",
    "    corr_df['FDR'] = multest.fdrcorrection(corr_df['p_value'])[1]\n",
    "    #corr_df['FDR'] = mulcomp.multipletests(corr_df['p_value'], method='bonferroni')[1]\n",
    "    corr_df['negLog10_FDR'] = corr_df['FDR'].map(lambda x: -np.log10(x))\n",
    "    \n",
    "    ## represent data with short format\n",
    "    for col in ['corrE','corrIE','corrEZ','corrIEZ','Zobs(TCPS)','negLog10_FDR']:\n",
    "        corr_df[col] = corr_df[col].map(lambda x: '{:.5f}'.format(x))\n",
    "    for col in ['p_value','FDR']:\n",
    "        corr_df[col] = corr_df[col].map(lambda x: '{:.5e}'.format(x))\n",
    "    \n",
    "    ## change columns with cell name\n",
    "    corr_df.columns=corr_df.columns+'_'+cell\n",
    "    corr_merged_df=pd.concat([corr_merged_df, corr_df], axis=1, sort=True)\n",
    "\n",
    "corr_merged_df.reset_index(inplace=True)\n",
    "corr_merged_df.columns=['TF1','TF2']+list(corr_merged_df.columns[2:])\n",
    "\n",
    "corr_merged_df.to_csv('result/TCP_score_viper/TCPS_merged_with_duplicates.txt',index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicates of TCP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dupDel=open('result/TCP_score_viper/TCPS_merged.txt','w+')\n",
    "\n",
    "tfPair=set()\n",
    "\n",
    "line_cnt=0\n",
    "dup_file=open('result/TCP_score_viper/TCPS_merged_with_duplicates.txt','r')\n",
    "for line in dup_file:\n",
    "    line_cnt+=1\n",
    "    if line_cnt==1:\n",
    "        _=dupDel.write(line)\n",
    "        continue\n",
    "        \n",
    "    tf1,tf2=line.split('\\t')[:2]\n",
    "    \n",
    "    if tf1==tf2:\n",
    "        continue\n",
    "        \n",
    "    if (tf1,tf2) not in tfPair:\n",
    "        _=dupDel.write(line)\n",
    "        tfPair.add((tf2,tf1))\n",
    "    else:\n",
    "        tfPair.remove((tf1,tf2))\n",
    "        \n",
    "dupDel.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### characterize significant TCPs with a certain FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TCPS_FDR=0.05\n",
    "\n",
    "sig_TCP=open('result/TCP_score_viper/sig_TCP.txt','w')\n",
    "sig_pos_TCP_both=[]\n",
    "sig_neg_TCP_both=[]\n",
    "\n",
    "TCPS=pd.read_table('result/TCP_score_viper/TCPS_merged.txt', sep='\\t',engine='python')\n",
    "TCPS.set_index(['TF1','TF2'], inplace=True)\n",
    "\n",
    "for cell in ['A375','HT29']:\n",
    "    sig_pos_TCP=list(TCPS.loc[(TCPS['FDR_{}'.format(cell)]<TCPS_FDR)&(TCPS['Zobs(TCPS)_{}'.format(cell)]>=0)].index)\n",
    "    sig_pos_TCP=['|'.join(sorted(TF_pair)) for TF_pair in sig_pos_TCP]\n",
    "    \n",
    "    sig_neg_TCP=list(TCPS.loc[(TCPS['FDR_{}'.format(cell)]<TCPS_FDR)&(TCPS['Zobs(TCPS)_{}'.format(cell)] <0)].index)\n",
    "    sig_neg_TCP=['|'.join(sorted(TF_pair)) for TF_pair in sig_neg_TCP]\n",
    "    \n",
    "    _=sig_TCP.write('{}(pos)\\t{}\\t{}\\n'.format(cell, len(sig_pos_TCP), ','.join(sig_pos_TCP)))\n",
    "    _=sig_TCP.write('{}(neg)\\t{}\\t{}\\n'.format(cell, len(sig_neg_TCP), ','.join(sig_neg_TCP)))\n",
    "    \n",
    "    sig_pos_TCP_both+=sig_pos_TCP\n",
    "    sig_neg_TCP_both+=sig_neg_TCP\n",
    "\n",
    "sig_pos_TCP_both=[TCP for TCP in set(sig_pos_TCP_both) if sig_pos_TCP_both.count(TCP)==2]\n",
    "sig_neg_TCP_both=[TCP for TCP in set(sig_neg_TCP_both) if sig_neg_TCP_both.count(TCP)==2]\n",
    "\n",
    "_=sig_TCP.write('both(pos)\\t{}\\t{}\\n'.format(len(sig_pos_TCP_both), ','.join(sig_pos_TCP_both)))\n",
    "_=sig_TCP.write('both(neg)\\t{}\\t{}\\n'.format(len(sig_neg_TCP_both), ','.join(sig_neg_TCP_both)))\n",
    "\n",
    "sig_TCP.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter in the significant TCPs in the both cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_TCP=pd.read_table('result/TCP_score_viper/sig_TCP.txt', sep='\\t', index_col=0)\n",
    "pos_TCP=sig_TCP.loc['both(pos)'].iloc[1].split(',')\n",
    "pos_TCP=[tuple(TCP.split('|')) for TCP in pos_TCP]\n",
    "neg_TCP=sig_TCP.loc['both(neg)'].iloc[1].split(',')\n",
    "neg_TCP=[tuple(TCP.split('|')) for TCP in neg_TCP]\n",
    "\n",
    "TCP_all_data=pd.read_table('result/TCP_score_viper/TCPS_merged.txt', index_col=[0,1], sep='\\t')\n",
    "TCP_flt_data=TCP_all_data.loc[pos_TCP+neg_TCP]\n",
    "\n",
    "## calculate the sum of the both FDR and sort by the FDR sum\n",
    "TCP_flt_data['negLog10_FDR_SUM']=TCP_flt_data['negLog10_FDR_A375']+TCP_flt_data['negLog10_FDR_HT29']\n",
    "TCP_flt_data.sort_values(by=['negLog10_FDR_SUM'], ascending=False, inplace=True)\n",
    "TCP_flt_data['negLog10_FDR_SUM']=TCP_flt_data['negLog10_FDR_SUM'].map(lambda x: '{:.3f}'.format(x))\n",
    "\n",
    "## save the result file\n",
    "TCP_flt_data.reset_index(inplace=True)\n",
    "TCP_flt_data.to_csv('result/TCP_score_viper/TCPS_merged_for_only_significant.txt',sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
