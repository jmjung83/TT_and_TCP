{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Creating directory C:\\Users\\jmjun\\AppData\\Local\\bioservices\\bioservices \n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.stats as sci\n",
    "import math\n",
    "import statsmodels.stats.multitest as multest\n",
    "import statsmodels.sandbox.stats.multicomp as mulcomp\n",
    "import networkx as nx\n",
    "import gseapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypergeomeric tests for the significant TCPs with TSgene, TTD and uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSgene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperGeo_TSgene(all_prots, sig_prots, sig_or_ran, pos_or_neg, res_file):\n",
    "    TSgene=pd.read_table('data/TSgene2.0/Human_TSGs.txt', sep='\\t',index_col=0,engine='python')\n",
    "    TSgene=set(TSgene['GeneSymbol'])\n",
    "    TSgene=all_prots&TSgene\n",
    "\n",
    "    p_val = sci.hypergeom.sf(len(sig_prots&TSgene), len(all_prots), len(TSgene), len(sig_prots))\n",
    "    \n",
    "    res_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(sig_or_ran, pos_or_neg, 'TSgene', len(all_prots),\n",
    "                                                                 len(TSgene), len(sig_prots), len(sig_prots&TSgene), p_val, sig_prots&TSgene))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TTD():\n",
    "    def cancer_related_disease(x):\n",
    "        code_list=[]\n",
    "        for code in x.split(', '):\n",
    "            code_list+=code.split('-')\n",
    "\n",
    "        for code in code_list:\n",
    "            if code.startswith('C') or code.startswith('D') :\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    TTD_to_UPT=pd.read_table('data/TTD/P2-01-TTD_uniprot_all.txt', index_col=0, sep='\\t',engine='python')\n",
    "    TTD_to_UPT=TTD_to_UPT['Uniprot ID'].map(lambda x: x.split(' ')[0]).to_dict()\n",
    "    UPT_to_gene=pd.read_table('data/TTD/uniprot_to_gene.txt', index_col=0, sep='\\t',engine='python')\n",
    "    UPT_to_gene=UPT_to_gene['To'].to_dict()\n",
    "\n",
    "    TTD_TarDis=pd.read_table('data/TTD/P1-05-Target_disease.txt', sep='\\t',engine='python')\n",
    "    TTD_TarDis=TTD_TarDis.loc[TTD_TarDis['ICD10'].notnull()]\n",
    "    TTD_TarDis=TTD_TarDis.loc[TTD_TarDis['ICD10'].map(cancer_related_disease)]\n",
    "\n",
    "    TTD_available_UPT=set(TTD_TarDis['TTDTargetID'])&set(TTD_to_UPT.keys())\n",
    "\n",
    "    UPT_list=[]\n",
    "    for TTD in TTD_available_UPT:\n",
    "        UPT_list.append(TTD_to_UPT[TTD])\n",
    "\n",
    "    UPT_available_gene=set(UPT_list)&set(UPT_to_gene.keys())\n",
    "\n",
    "    gene_list=[]\n",
    "    for UPT in UPT_available_gene:\n",
    "        gene_list.append(UPT_to_gene[UPT])\n",
    "\n",
    "    return set(gene_list)\n",
    "\n",
    "def hyperGeo_TTD(all_prots, sig_prots, sig_or_ran, pos_or_neg, res_file):\n",
    "    TTD=get_TTD()\n",
    "    TTD=all_prots&TTD\n",
    "    \n",
    "    p_val = sci.hypergeom.sf(len(sig_prots&TTD), len(all_prots), len(TTD), len(sig_prots))\n",
    "    \n",
    "    res_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(sig_or_ran, pos_or_neg, 'TTD',len(all_prots),\n",
    "                                                                 len(TTD), len(sig_prots), len(sig_prots&TTD), p_val, sig_prots&TTD))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniprot(status):\n",
    "    uniprot=pd.read_table('data/Uniprot/{}_uniprot.txt'.format(status), sep='\\t',engine='python')\n",
    "    uniprot=uniprot.loc[uniprot['Gene names'].notnull()]\n",
    "    \n",
    "    uniprot_list=[]\n",
    "    for ind, row in uniprot.iterrows():\n",
    "        uniprot_list+=row['Gene names'].split(' ')\n",
    "\n",
    "    return set(uniprot_list)\n",
    "\n",
    "def hyperGeo_Uniprot(all_prots, sig_prots, status, sig_or_ran, pos_or_neg, res_file):\n",
    "    uniprot=get_uniprot(status)\n",
    "    uniprot=all_prots&uniprot\n",
    "    \n",
    "    p_val = sci.hypergeom.sf(len(sig_prots&uniprot), len(all_prots), len(uniprot), len(sig_prots))\n",
    "    \n",
    "    res_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(sig_or_ran, pos_or_neg, 'uniprot({})'.format(status), len(all_prots),\n",
    "                                                                 len(uniprot), len(sig_prots), len(sig_prots&uniprot), p_val, sig_prots&uniprot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constructing a PPI network based on twohybird interactions in BIOGRID database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppi_nx():\n",
    "    ppi=pd.read_table('data/BIOGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.186.tab3.txt', sep='\\t')\n",
    "\n",
    "    ppi_twohyb=ppi.loc[ppi['Experimental System']=='Two-hybrid']\n",
    "    ppi_twohyb=ppi_twohyb[['Official Symbol Interactor A','Official Symbol Interactor B']]\n",
    "    ppi_twohyb.columns=['p1','p2']\n",
    "\n",
    "    # construct ppi network\n",
    "    ppi_nx=nx.Graph()\n",
    "    for ind in ppi_twohyb.index:\n",
    "        p1=ppi_twohyb.loc[ind,'p1']\n",
    "        p2=ppi_twohyb.loc[ind,'p2']\n",
    "        ppi_nx.add_edge(p1, p2)\n",
    "    \n",
    "    return ppi_nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting proteins on the paths between the target genes of TF.A and TF. B in the PPI network, where TF.A and TF.B are the significantg TCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_on_path(ppi_nx, g, p, path_len):\n",
    "    if (g not in ppi_nx.nodes()) or (p not in ppi_nx.nodes()):\n",
    "        return []\n",
    "    paths=nx.all_simple_paths(ppi_nx, g, p, cutoff=path_len) # get all simple path between g and p\n",
    "    protein_list=[]\n",
    "    for path in paths:\n",
    "        protein_list+=path[:-1]\n",
    "    return protein_list\n",
    "\n",
    "def get_proteins_on_path_between_TCP(sig_or_ran,ppi_nx,neg_or_pos, path_len, sig_cnt_perc):\n",
    "    sig_TCP=pd.read_table('result/TCP_score_viper/sig_TCP.txt', sep='\\t',index_col=0,header=None, engine='python')\n",
    "    sig_TCP=sig_TCP.loc['both({})'.format(neg_or_pos)].iloc[1].split(',')\n",
    "\n",
    "    ## randomly selected TCP\n",
    "    # if sig_or_ran is 'ran', TF pairs are randomly selected as many as the significant TCPs\n",
    "    if 'ran' in sig_or_ran:\n",
    "        TF_df=pd.read_table('result/TT_score_viper/TTS_A375.txt', sep='\\t',index_col=0,engine='python')\n",
    "        TF_list=list(TF_df.index)\n",
    "        ranTF_list=np.random.choice(TF_list, len(sig_TCP)*2, replace=False)\n",
    "        ranTCP=[]\n",
    "        for ii in range(int(len(ranTF_list)/2)):\n",
    "            ranTCP.append(ranTF_list[ii*2]+'|'+ranTF_list[ii*2+1])\n",
    "        sig_TCP=ranTCP[:]\n",
    "    print(sig_TCP[:5])\n",
    "    \n",
    "    # get proteins on the all paths whose length is lesser than 'path_len' between TF.A and the target genes of TF.B\n",
    "    tf_target=pd.read_table('data/TRRUST2_TF/trrust2_TF_target_processed.txt', sep='\\t',index_col=0)\n",
    "    all_protein_list=[]\n",
    "    for p1_p2 in sig_TCP:\n",
    "        protein_list_for_each_TCP=[]\n",
    "        p1,p2=p1_p2.split('|')\n",
    "        for g1 in tf_target.loc[p1,['target']].values.flatten():\n",
    "            protein_list_for_each_TCP+=get_protein_on_path(ppi_nx, g1, p2, path_len)\n",
    "        for g2 in tf_target.loc[p2,['target']].values.flatten():\n",
    "            protein_list_for_each_TCP+=get_protein_on_path(ppi_nx, g2, p1, path_len)\n",
    "        all_protein_list+=list(set(protein_list_for_each_TCP))\n",
    "    \n",
    "    prot_cnt_dic={}\n",
    "    for prot in set(all_protein_list):\n",
    "        prot_cnt_dic[prot]=all_protein_list.count(prot)\n",
    "    \n",
    "    prot_cnt_sr=pd.Series(prot_cnt_dic)\n",
    "    sig_prot_sr=prot_cnt_sr.loc[prot_cnt_sr>=(len(sig_TCP)*sig_cnt_perc)]\n",
    "    \n",
    "    # return unique proteins on the pahts\n",
    "    return set(sig_prot_sr.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig\n",
      "['IFI16|MXI1', 'POU2F2|POU4F1', 'NFIL3|POU2F2', 'FOXP3|NFATC3', 'BACH2|PGR']\n",
      "['ENO1|HOXA1', 'SFPQ|SPDEF', 'E2F6|TFDP1', 'AATF|ENO1', 'FOXL2|SOX17']\n",
      "ran1\n",
      "['KLF8|TRIM16', 'RBPJ|THRB', 'LDB1|TCF7L2', 'EAPP|NCOA2', 'KLF6|ERG']\n",
      "['STAT4|AIP', 'TBX21|ISL1', 'FOXG1|ELF2', 'GFI1B|KLF6', 'ZNF202|KDM4C']\n",
      "ran2\n",
      "['OTX2|USF2', 'ZNF224|UHRF1', 'PIAS1|ID4', 'TOP2B|GCM1', 'NR3C1|TCF7L2']\n",
      "['BARD1|DNMT3L', 'HIC1|CREB3L1', 'NFYA|NFIB', 'FOSL2|ZNF382', 'GTF3A|FOXF1']\n",
      "ran3\n",
      "['HOXA7|MYOD1', 'ANKRD1|HMGA2', 'DUX4|TBX5', 'HSF2|HINFP', 'NFYC|SP7']\n",
      "['PAX2|KLF5', 'ID4|FOXI1', 'MTF1|CBX8', 'SOX6|MECP2', 'NANOG|PITX1']\n",
      "ran4\n",
      "['TRAF6|FOXP3', 'HINFP|POU5F1', 'CREBBP|HNF4G', 'ONECUT2|KAT5', 'CBFA2T3|RUNX2']\n",
      "['HDAC11|LMO4', 'SPDEF|VHL', 'CTBP1|SOX6', 'SALL3|COPS5', 'SOX17|HNF4G']\n",
      "ran5\n",
      "['PROX1|CEBPA', 'MTA3|ZBTB5', 'ESR2|RELB', 'TCF3|ATOH1', 'MZF1|CDX2']\n",
      "['MXD1|HHEX', 'DAXX|ERF', 'MED23|UHRF1', 'ASCL1|SALL4', 'SATB1|MTA1']\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ppi_nx=get_ppi_nx()\n",
    "all_prots=set(list(ppi_nx.nodes()))\n",
    "\n",
    "res_file=open('result/TCP_score_viper/hyperGeo_result.txt','w+')\n",
    "_=res_file.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format('sig_or_ran','sig_TCP_type','database','all_prot','GS','sig_prot','hit','p-value','hit_prot_list'))\n",
    "\n",
    "path_len=3\n",
    "sig_cnt_perc=0.2\n",
    "\n",
    "ran_num=5000\n",
    "\n",
    "# 1 significant TCPs and 5000 randomly selected TF pairs to compute empirical p-value of the significant TCPs\n",
    "for sig_or_ran in ['sig']+['ran{}'.format(ii) for ii in range(1,ran_num+1)]:\n",
    "    print(sig_or_ran)\n",
    "    sig_pos_prots=get_proteins_on_path_between_TCP(sig_or_ran, ppi_nx, 'pos', path_len, sig_cnt_perc)\n",
    "    hyperGeo_TSgene(all_prots, sig_pos_prots, sig_or_ran, 'pos', res_file)\n",
    "    hyperGeo_Uniprot(all_prots, sig_pos_prots, 'tumor_suppressor', sig_or_ran, 'pos', res_file)\n",
    "    \n",
    "    sig_neg_prots=get_proteins_on_path_between_TCP(sig_or_ran, ppi_nx, 'neg', path_len, sig_cnt_perc)\n",
    "    hyperGeo_TTD(all_prots, sig_neg_prots, sig_or_ran, 'neg', res_file)\n",
    "    hyperGeo_Uniprot(all_prots, sig_neg_prots, 'oncogene', sig_or_ran, 'neg', res_file)\n",
    "    \n",
    "res_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biological process enrichment for TFs in BTCPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of TF in the sig TCPs:  147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gseapy.enrichr.Enrichr at 0x231da983148>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<gseapy.enrichr.Enrichr at 0x231da530488>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sig_TCP():\n",
    "    sig_TCP=pd.read_table('result/TCP_score_viper/sig_TCP.txt', sep='\\t',index_col=0,header=None)\n",
    "    \n",
    "    TF_list=[]\n",
    "    \n",
    "    pos_sig_TCP=sig_TCP.loc['both(pos)'].iloc[1]\n",
    "    for TF_pair in pos_sig_TCP.split(','):\n",
    "        TF_list+=TF_pair.split('|')\n",
    "        \n",
    "    neg_sig_TCP=sig_TCP.loc['both(neg)'].iloc[1]\n",
    "    for TF_pair in neg_sig_TCP.split(','):\n",
    "        TF_list+=TF_pair.split('|')\n",
    "        \n",
    "    return list(set(TF_list))\n",
    "\n",
    "TF_list=get_sig_TCP()\n",
    "print('# of TF in the sig TCPs: ',len(TF_list))\n",
    "\n",
    "gseapy.enrichr(gene_list=TF_list, gene_sets='KEGG_2019_Human',            outdir='result/TCP_score_viper/pathway_enrichment/')\n",
    "gseapy.enrichr(gene_list=TF_list, gene_sets='GO_Biological_Process_2018', outdir='result/TCP_score_viper/pathway_enrichment/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
